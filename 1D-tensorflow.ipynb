{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T14:41:39.671554Z",
     "start_time": "2019-03-19T14:41:38.382985Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T14:41:40.087708Z",
     "start_time": "2019-03-19T14:41:39.675891Z"
    }
   },
   "outputs": [],
   "source": [
    "trainD = np.load(\"/home/hsiehch/30s/train_data.npy\")\n",
    "trainL = np.load(\"/home/hsiehch/30s/train_label.npy\")\n",
    "validationD = np.load(\"/home/hsiehch/30s/validation_data.npy\")\n",
    "validationL = np.load(\"/home/hsiehch/30s/validation_label.npy\")\n",
    "testD = np.load(\"/home/hsiehch/30s/test_data.npy\")\n",
    "testL = np.load(\"/home/hsiehch/30s/test_label.npy\")\n",
    "\n",
    "trainData = trainD.reshape((trainD.shape[0], trainD.shape[1], 1))\n",
    "trainLabel = np_utils.to_categorical(trainL, 4)\n",
    "validationData = validationD.reshape((validationD.shape[0], validationD.shape[1], 1))\n",
    "validationLabel = np_utils.to_categorical(validationL, 4)\n",
    "testData = testD.reshape((testD.shape[0], testD.shape[1], 1))\n",
    "testLabel = np_utils.to_categorical(testL, 4)\n",
    "\n",
    "print('Train Data:', trainData.shape)\n",
    "print('Train Label: ', trainLabel.shape)\n",
    "print('Vali Data: ', validationData.shape)\n",
    "print('Vali Label: ', validationLabel.shape)\n",
    "print('Test Data: ', testData.shape)\n",
    "print('Test Label: ', testLabel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T14:41:43.770293Z",
     "start_time": "2019-03-19T14:41:40.090243Z"
    }
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    inputs = tf.placeholder(dtype=tf.float32, shape=(None, 9000, 1), name='inputs')\n",
    "    labels = tf.placeholder(dtype=tf.float32, shape=(None, 4), name='labels')    \n",
    "\n",
    "    conv1 = tf.layers.conv1d(inputs, filters=32, kernel_size=7, padding='valid', activation=tf.nn.relu, name='conv1d_1')\n",
    "    max_pool_1 = tf.layers.max_pooling1d(conv1, pool_size=2, strides=2)\n",
    "    \n",
    "    conv2 = tf.layers.conv1d(max_pool_1, filters=32, kernel_size=7, padding='valid', activation=tf.nn.relu, name='conv1d_2')\n",
    "    max_pool_2 = tf.layers.max_pooling1d(conv2, pool_size=2, strides=2)\n",
    "    \n",
    "    conv3 = tf.layers.conv1d(max_pool_2, filters=64, kernel_size=7, padding='valid', activation=tf.nn.relu, name='conv1d_3')\n",
    "    max_pool_3 = tf.layers.max_pooling1d(conv3, pool_size=2, strides=2)\n",
    "    \n",
    "    conv4 = tf.layers.conv1d(max_pool_3, filters=64, kernel_size=3, padding='valid', activation=tf.nn.relu, name='conv1d_4')\n",
    "    max_pool_4 = tf.layers.max_pooling1d(conv4, pool_size=2, strides=2)\n",
    "    \n",
    "    conv5 = tf.layers.conv1d(max_pool_4, filters=128, kernel_size=3, padding='valid', activation=tf.nn.relu, name='conv1d_5')\n",
    "    max_pool_5 = tf.layers.max_pooling1d(conv5, pool_size=2, strides=2)\n",
    "    \n",
    "    conv6 = tf.layers.conv1d(max_pool_5, filters=128, kernel_size=3, padding='valid', activation=tf.nn.relu, name='conv1d_6')\n",
    "    max_pool_6 = tf.layers.max_pooling1d(conv6, pool_size=2, strides=2)\n",
    "    dropout_1 = tf.layers.dropout(max_pool_6, rate=0.5)\n",
    "    \n",
    "    conv7 = tf.layers.conv1d(dropout_1, filters=256, kernel_size=3, padding='valid', activation=tf.nn.relu, name='conv1d_7')\n",
    "    max_pool_7 = tf.layers.max_pooling1d(conv7, pool_size=2, strides=2)\n",
    "    \n",
    "    conv8 = tf.layers.conv1d(max_pool_7, filters=256, kernel_size=3, padding='valid', activation=tf.nn.relu, name='conv1d_8')\n",
    "    max_pool_8 = tf.layers.max_pooling1d(conv8, pool_size=2, strides=2)\n",
    "    dropout_2 = tf.layers.dropout(max_pool_8, rate=0.5)\n",
    "    \n",
    "    conv9 = tf.layers.conv1d(dropout_2, filters=512, kernel_size=3, padding='valid', activation=tf.nn.relu, name='conv1d_9')\n",
    "    max_pool_9 = tf.layers.max_pooling1d(conv9, pool_size=2, strides=2)\n",
    "    dropout_3 = tf.layers.dropout(max_pool_9, rate=0.5)\n",
    "    \n",
    "    conv10 = tf.layers.conv1d(dropout_3, filters=512, kernel_size=3, padding='valid', activation=tf.nn.relu, name='conv1d_10')\n",
    "    \n",
    "    flatten = tf.contrib.layers.flatten(conv10)\n",
    "    dense_1 = tf.layers.dense(inputs=flatten, units=128, activation=tf.nn.relu)\n",
    "    dropout_4 = tf.layers.dropout(dense_1, rate=0.5)\n",
    "    dense_2 = tf.layers.dense(inputs=dropout_4, units=32, activation=tf.nn.relu)\n",
    "    output = tf.layers.dense(inputs=dense_2, units=4)\n",
    "    output_1 = tf.contrib.layers.softmax(output)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=output, labels=labels))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    " \n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(output_1, 1), tf.argmax(labels, 1))\n",
    "    cast_ = tf.cast(correct_pred, tf.float32)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T14:41:43.777196Z",
     "start_time": "2019-03-19T14:41:43.772354Z"
    }
   },
   "outputs": [],
   "source": [
    "iteration = 100\n",
    "batch_size = 70\n",
    "\n",
    "train_length = trainData.shape[0]\n",
    "start = 0\n",
    "end = batch_size\n",
    "\n",
    "def batch_generation(data_length):\n",
    "    row = data_length//batch_size\n",
    "    col = batch_size\n",
    "    arr = np.arange(row*col)\n",
    "    np.random.shuffle(arr)\n",
    "    arr = arr.reshape((row, col))\n",
    "    return arr\n",
    "\n",
    "batch_index = batch_generation(trainData.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T14:45:45.776953Z",
     "start_time": "2019-03-19T14:44:25.869157Z"
    }
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    batch_index = batch_generation(trainData.shape[0])\n",
    "    for epoch in range(iteration):\n",
    "        for index in batch_index:\n",
    "            loss, opt, acc = sess.run([cost, optimizer, accuracy],\n",
    "                             feed_dict={inputs: trainData[index],\n",
    "                                        labels: trainLabel[index]\n",
    "                                    })   \n",
    "        \n",
    "        val_loss, val_acc = sess.run([cost, accuracy],\n",
    "                             feed_dict={inputs: validationData,\n",
    "                                        labels: validationLabel\n",
    "                                    })\n",
    "\n",
    "        print(\"Epoch: {}/{}\".format(epoch+1, iteration))\n",
    "        print(\"loss:\", \"{:9f}\".format(loss), \"-\", \"acc:\", acc, \"-\",\n",
    "              \"val_loss:\", \"{:9f}\".format(val_loss), \"-\", \"val_acc:\", val_acc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T13:35:14.220245Z",
     "start_time": "2019-01-12T13:35:12.373137Z"
    }
   },
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tensor_name_list = [tensor.name for tensor in tf.get_default_graph().as_graph_def().node]\n",
    "    for tensor_name in tensor_name_list:\n",
    "        print(tensor_name,'\\n')\n",
    "\n",
    "#     bar = tf.get_default_graph().get_tensor_by_name('Flatten/flatten/Reshape:0')\n",
    "#     print(bar)\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "\n",
    "    bar = tf.get_default_graph().get_tensor_by_name('conv1d_1/Relu:0')\n",
    "    print(bar)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T13:35:14.268207Z",
     "start_time": "2019-01-12T13:35:14.254128Z"
    }
   },
   "source": [
    "def summary():\n",
    "    layer_name = 'conv1d_'\n",
    "    layers = []\n",
    "    counter = 1\n",
    "    for tensor in tf.get_default_graph().as_graph_def().node:\n",
    "        if tensor.name == layer_name+str(counter)+'/Relu':\n",
    "            layers.append(tensor.name)\n",
    "            counter += 1\n",
    "        if tensor.name == \"Flatten/flatten/Reshape\":\n",
    "            layers.append(tensor.name)\n",
    "    for tensor_name in layers:\n",
    "        print(tensor_name, tf.get_default_graph().get_tensor_by_name(tensor_name+':0').shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
